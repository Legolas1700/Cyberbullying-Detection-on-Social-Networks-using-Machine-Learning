# -*- coding: utf-8 -*-
"""Cyberbullying_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zj2Xrec1IHCi68uKIcJCFYtSQHNEAQ6j

Libraries
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer

import nltk
nltk.download('stopwords')

nltk.download('wordnet')

data = pd.read_csv("cyberbullying_dataset.csv")

"""Data exploration & visualization"""

import matplotlib.pyplot as plt
import seaborn as sns

print("First 5 rows of the dataset:")
print(data.head())

print("\nDataset information:")
print(data.info())

print("\nDescriptive statistics for numerical columns:")
print(data.describe())

print("\nDistribution of Cyberbullying labels:")
print(data['Is_Cyberbullying'].value_counts())

plt.figure(figsize=(8, 6))
plt.pie(data['Is_Cyberbullying'].value_counts(), labels=['Non-Cyberbullying', 'Cyberbullying'], autopct='%1.1f%%')
plt.title('Distribution of Cyberbullying Labels')
plt.show()

plt.figure(figsize=(8, 6))
sns.countplot(x='Is_Cyberbullying', data=data)
plt.title('Distribution of Cyberbullying Labels')
plt.xlabel('Is_Cyberbullying (0: Non-Cyberbullying, 1: Cyberbullying)')
plt.ylabel('Count')
plt.show()

data['Text_Length'] = data['Text'].apply(len)

plt.figure(figsize=(10, 6))
sns.histplot(data['Text_Length'], bins=50, kde=True)
plt.title('Distribution of Text Lengths')
plt.xlabel('Text Length')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(x='Is_Cyberbullying', y='Text_Length', data=data)
plt.title('Text Length vs. Cyberbullying')
plt.xlabel('Is_Cyberbullying (0: Non-Cyberbullying, 1: Cyberbullying)')
plt.ylabel('Text Length')
plt.show()

print("\nValue counts for 'Label' column:")
print(data['Label'].value_counts())

plt.figure(figsize=(12, 6))
sns.countplot(x='Label', data=data)
plt.title('Distribution of Labels')
plt.xlabel('Label')
plt.ylabel('Count')
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for readability
plt.show()

"""Data cleaning and preprocessing"""

import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import pandas as pd

def preprocess_text(text):
    text = str(text).lower()
    text = re.sub(r'<.*?>', ' ', text)                    # strip HTML
    text = re.sub(r'http\S+|www\S+|https\S+', ' ', text)  # remove URLs
    text = re.sub(r'[^a-zA-Z\s]', ' ', text)              # keep only letters/spaces
    text = re.sub(r'\s+', ' ', text).strip()

    # simple regex tokenizer instead of word_tokenize
    tokens = re.findall(r'\b[a-z]{2,}\b', text)

    # stopwords
    try:
        stop_words = set(stopwords.words('english'))
    except:
        stop_words = {"the","and","is","in","it","of","to","a","that","this","for","on","with","as","are","was","my","i"}

    tokens = [w for w in tokens if w not in stop_words]

    # lemmatization
    try:
        lemmatizer = WordNetLemmatizer()
        tokens = [lemmatizer.lemmatize(w) for w in tokens]
    except:
        tokens = tokens  # fallback if wordnet missing

    return ' '.join(tokens)


data = pd.read_csv("cyberbullying_dataset.csv")

print("\n1. Lowercasing:")
print("Before:\n", data['Text'][0])
data['Text_Lower'] = data['Text'].str.lower()
print("After:\n", data['Text_Lower'][0])

print("\n2. Removing HTML Tags:")
print("Before:\n", data['Text'][10])  # Example with potential HTML
data['Text_NoHTML'] = data['Text'].apply(lambda x: re.sub(r'<.*?>', '', x))
print("After:\n", data['Text_NoHTML'][10])

print("\n3. Removing URLs:")
print("Before:\n", data['Text'][20])  # Example with a URL
data['Text_NoURLs'] = data['Text'].apply(lambda x: re.sub(r'http\S+|www\S+|https\S+', '', x, flags=re.IGNORECASE))
print("After:\n", data['Text_NoURLs'][20])

print("\n4. Removing Special Characters:")
print("Before:\n", data['Text'][30])  # Example with special characters
data['Text_NoSpecChars'] = data['Text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\s]', '', x))
print("After:\n", data['Text_NoSpecChars'][30])

print("\n5. Removing Extra Whitespace:")
print("Before:\n", data['Text'][40])  # Example with extra spaces
data['Text_NoExtraWS'] = data['Text'].apply(lambda x: re.sub(r'\s+', ' ', x).strip())
print("After:\n", data['Text_NoExtraWS'][40])

!pip install nltk
import nltk

nltk.download('punkt_tab')  # Download the punkt_tab data

print("\n6. Tokenization:")
print("Before:\n", data['Text'][50])
data['Text_Tokenized'] = data['Text'].apply(word_tokenize)
print("After:\n", data['Text_Tokenized'][50])

print("\n7. Removing Stop Words:")
stop_words = set(stopwords.words('english'))
print("Before:\n", data['Text_Tokenized'][60])
data['Text_NoStopWords'] = data['Text_Tokenized'].apply(lambda tokens: [word for word in tokens if word not in stop_words])
print("After:\n", data['Text_NoStopWords'][60])

print("\n8. Lemmatization:")
lemmatizer = WordNetLemmatizer()
print("Before:\n", data['Text_NoStopWords'][70])
data['Text_Lemmatized'] = data['Text_NoStopWords'].apply(lambda tokens: [lemmatizer.lemmatize(word) for word in tokens])
print("After:\n", data['Text_Lemmatized'][70])

print("\nFinal Preprocessed Text:")
final_preprocessing = data['Text'].apply(preprocess_text)
print(final_preprocessing[0])

import re
data['Cleaned_Text'] = data['Text'].apply(preprocess_text)

label_encoder = LabelEncoder()
data['Is_Cyberbullying_Encoded'] = label_encoder.fit_transform(data['Is_Cyberbullying'])

"""train and test split & feature extraction"""

X_train, X_test, y_train, y_test = train_test_split(
    data['Cleaned_Text'], data['Is_Cyberbullying_Encoded'], test_size=0.2, random_state=42, stratify=data['Is_Cyberbullying_Encoded']
)

tfidf_vectorizer = TfidfVectorizer()
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

"""Model defining, training and evaluation"""

models = {
    'Naive Bayes': MultinomialNB(),
    'SVM': SVC(kernel='linear', random_state=42),
    'Extra Trees': ExtraTreesClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42)
}

# Train the models
trained_models = {}
for model_name, model in models.items():
    model.fit(X_train_tfidf, y_train)
    trained_models[model_name] = model

nb_model = MultinomialNB()
nb_model.fit(X_train_tfidf, y_train)
nb_predictions = nb_model.predict(X_test_tfidf)

nb_accuracy = accuracy_score(y_test, nb_predictions)
nb_precision = precision_score(y_test, nb_predictions)
nb_recall = recall_score(y_test, nb_predictions)
nb_f1 = f1_score(y_test, nb_predictions)
nb_confusion = confusion_matrix(y_test, nb_predictions)

print("Naive Bayes Results:")
print(f"Accuracy: {nb_accuracy:.4f}")
print(f"Precision: {nb_precision:.4f}")
print(f"Recall: {nb_recall:.4f}")
print(f"F1 Score: {nb_f1:.4f}")
print("Confusion Matrix:")
print(nb_confusion)

nb_results = {
    'Model': 'Naive Bayes',
    'Accuracy': nb_accuracy,
    'Precision': nb_precision,
    'Recall': nb_recall,
    'F1 Score': nb_f1
}

svm_model = SVC(kernel='linear', random_state=42)
svm_model.fit(X_train_tfidf, y_train)
svm_predictions = svm_model.predict(X_test_tfidf)

svm_accuracy = accuracy_score(y_test, svm_predictions)
svm_precision = precision_score(y_test, svm_predictions)
svm_recall = recall_score(y_test, svm_predictions)
svm_f1 = f1_score(y_test, svm_predictions)
svm_confusion = confusion_matrix(y_test, svm_predictions)

print("\nSVM Results:")
print(f"Accuracy: {svm_accuracy:.4f}")
print(f"Precision: {svm_precision:.4f}")
print(f"Recall: {svm_recall:.4f}")
print(f"F1 Score: {svm_f1:.4f}")
print("Confusion Matrix:")
print(svm_confusion)

svm_results = {
    'Model': 'SVM',
    'Accuracy': svm_accuracy,
    'Precision': svm_precision,
    'Recall': svm_recall,
    'F1 Score': svm_f1
}

et_model = ExtraTreesClassifier(random_state=42)
et_model.fit(X_train_tfidf, y_train)
et_predictions = et_model.predict(X_test_tfidf)

et_accuracy = accuracy_score(y_test, et_predictions)
et_precision = precision_score(y_test, et_predictions)
et_recall = recall_score(y_test, et_predictions)
et_f1 = f1_score(y_test, et_predictions)
et_confusion = confusion_matrix(y_test, et_predictions)

print("\nExtra Trees Results:")
print(f"Accuracy: {et_accuracy:.4f}")
print(f"Precision: {et_precision:.4f}")
print(f"Recall: {et_recall:.4f}")
print(f"F1 Score: {et_f1:.4f}")
print("Confusion Matrix:")
print(et_confusion)

et_results = {
    'Model': 'Extra Trees',
    'Accuracy': et_accuracy,
    'Precision': et_precision,
    'Recall': et_recall,
    'F1 Score': et_f1
}

rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train_tfidf, y_train)
rf_predictions = rf_model.predict(X_test_tfidf)

rf_accuracy = accuracy_score(y_test, rf_predictions)
rf_precision = precision_score(y_test, rf_predictions)
rf_recall = recall_score(y_test, rf_predictions)
rf_f1 = f1_score(y_test, rf_predictions)
rf_confusion = confusion_matrix(y_test, rf_predictions)

print("\nRandom Forest Results:")
print(f"Accuracy: {rf_accuracy:.4f}")
print(f"Precision: {rf_precision:.4f}")
print(f"Recall: {rf_recall:.4f}")
print(f"F1 Score: {rf_f1:.4f}")
print("Confusion Matrix:")
print(rf_confusion)

rf_results = {
    'Model': 'Random Forest',
    'Accuracy': rf_accuracy,
    'Precision': rf_precision,
    'Recall': rf_recall,
    'F1 Score': rf_f1
}

"""Model Comparison and Visualization"""

model_results = [nb_results, svm_results, et_results, rf_results]
model_df = pd.DataFrame(model_results)

print(model_df)

plt.figure(figsize=(12, 6))
sns.barplot(x='Model', y='F1 Score', data=model_df)
plt.title('Model Comparison (F1 Score)')
plt.ylim(0, 1)
plt.show()

plt.figure(figsize=(12, 6))
sns.barplot(x='Model', y='Accuracy', data=model_df)
plt.title('Model Comparison (Accuracy)')
plt.ylim(0, 1)
plt.show()

model_results = [nb_results, svm_results, et_results, rf_results]
model_df = pd.DataFrame(model_results)

print(model_df)

def evaluate_best_model(model_evaluation_results):
    """
    Evaluates and compares the models to determine the best one based on overall performance.

    Args:
        model_evaluation_results (dict): A dictionary containing the evaluation results for each model.
            The dictionary should have the following structure:
            {
                'ModelName1': {'Accuracy': ..., 'Precision': ..., 'Recall': ..., 'F1-Score': ...},
                'ModelName2': {'Accuracy': ..., 'Precision': ..., 'Recall': ..., 'F1-Score': ...},
                ...
            }

    Returns:
        str: The name of the best model.
    """
    if not model_evaluation_results:
        print("Error: No model evaluation results provided.")
        return None

    # Define weights for each metric (you can adjust these)
    weights = {
        'Accuracy': 0.25,
        'Precision': 0.25,
        'Recall': 0.25,
        'F1 Score': 0.25,
    }

    # Calculate a weighted score for each model
    model_scores = {}
    for model, metrics in model_evaluation_results.items():
        weighted_score = 0
        for metric, value in metrics.items():
            if metric in weights:
                weighted_score += weights[metric] * value
        model_scores[model] = weighted_score

    # Determine the best model
    best_model = max(model_scores, key=model_scores.get)
    best_score = model_scores[best_model]

    print("\nModel Scores:")
    for model, score in model_scores.items():
        print(f"{model}: {score:.4f}")

    print(f"\nBest Model (based on weighted score): {best_model}")
    print(f"  Weighted Score: {best_score:.4f}")

    return best_model

# Example Usage (replace with your actual data)
model_evaluation_results = {
    'Naive Bayes': {'Accuracy': nb_accuracy, 'Precision': nb_precision, 'Recall': nb_recall, 'F1 Score': nb_f1},
    'SVM': {'Accuracy': svm_accuracy, 'Precision': svm_precision, 'Recall': svm_recall, 'F1 Score': svm_f1},
    'Random Forest': {'Accuracy': rf_accuracy, 'Precision': rf_precision, 'Recall': rf_recall, 'F1 Score': rf_f1},
    'Extra Trees': {'Accuracy': et_accuracy, 'Precision': et_precision, 'Recall': et_recall, 'F1 Score': et_f1},
}

best_model_name = evaluate_best_model(model_evaluation_results)

# Prepare data for visualization
model_names = list(model_evaluation_results.keys())
metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']
data = {
    model: [model_evaluation_results[model][metric] for metric in metrics]
    for model in model_names
}

# Create DataFrame for Seaborn
df = pd.DataFrame(data, index=metrics).T.reset_index().rename(columns={'index': 'Model'})

# Melt the DataFrame to long format for Seaborn
df_melted = df.melt('Model', var_name='Metric', value_name='Value')

# Plotting
plt.figure(figsize=(12, 6))
sns.barplot(x='Model', y='Value', hue='Metric', data=df_melted, palette='viridis')
plt.title('Model Comparison - Grouped Evaluation Metrics', fontsize=16)
plt.ylim(0.9, 1.01)  # Adjust y-axis limits to focus on the differences.  Change these if needed.
plt.ylabel('Score', fontsize=12)
plt.xlabel('Model', fontsize=12)
plt.legend(title='Metric', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)
plt.xticks(rotation=0, ha='center', fontsize=10)
plt.yticks(fontsize=10)

# Add value labels
for p in plt.gca().patches:
    height = p.get_height()
    if height > 0:
        plt.text(p.get_x() + p.get_width() / 2., height + 0.005, f'{height:.4f}',  # Format the values
                 ha='center', va='bottom', fontsize=8)

plt.tight_layout()
plt.show()

"""Evaluating best model"""

def evaluate_best_model(model_evaluation_results):
    """
    Evaluates the best model based on weighted performance metrics.

    Args:
        model_evaluation_results (dict): A dictionary containing the evaluation metrics for each model.
            Expected structure:
            {
                'Model Name': {
                    'Accuracy': float,
                    'Precision': float,
                    'Recall': float,
                    'F1 Score': float
                },
                ...
            }

    Returns:
        tuple: (best_model_name, best_model_accuracy)
               Returns the name of the best model and its accuracy.
    """
    weights = {
        'Accuracy': 0.2,
        'Precision': 0.25,
        'Recall': 0.25,
        'F1 Score': 0.3  # Giving F1 Score more weight
    }

    weighted_scores = {}
    for model_name, metrics in model_evaluation_results.items():
        weighted_score = 0
        for metric, value in metrics.items():
            if metric in weights:
                weighted_score += value * weights[metric]
        weighted_scores[model_name] = weighted_score

    best_model_name = max(weighted_scores, key=weighted_scores.get)
    best_model_accuracy = model_evaluation_results[best_model_name]['Accuracy'] #get accuracy

    return best_model_name, best_model_accuracy

# Example usage with your model_evaluation_results
model_evaluation_results = {
    'Naive Bayes': {
        'Accuracy': nb_accuracy,
        'Precision': nb_precision,
        'Recall': nb_recall,
        'F1 Score': nb_f1
    },
    'SVM': {
        'Accuracy': svm_accuracy,
        'Precision': svm_precision,
        'Recall': svm_recall,
        'F1 Score': svm_f1
    },
    'Extra Trees': {
        'Accuracy': et_accuracy,
        'Precision': et_precision,
        'Recall': et_recall,
        'F1 Score': et_f1
    },
    'Random Forest': {
        'Accuracy': rf_accuracy,
        'Precision': rf_precision,
        'Recall': rf_recall,
        'F1 Score': rf_f1
    }
}

best_model_name, best_model_accuracy = evaluate_best_model(model_evaluation_results)
print(f"The best model is: {best_model_name}")
print(f"The accuracy of the best model is: {best_model_accuracy:.4f}")

"""Prediction and Action Required Function"""

from sklearn.metrics.pairwise import cosine_similarity

def predict_and_get_action(input_text, model, vectorizer, dataframe, encoded_column_name='Is_Cyberbullying_Encoded', label_column_name='Label', text_column_name='Text'):
    preprocessed_input = preprocess_text(input_text)
    input_tfidf = vectorizer.transform([preprocessed_input])
    prediction = model.predict(input_tfidf)[0]
    probability = model.predict_proba(input_tfidf)[0][prediction]  # Get probability of the predicted class

    if prediction == 1:
        prediction_label = "Cyberbullying"
    else:
        prediction_label = "Non-Cyberbullying"

    # Find similar examples from the dataset
    all_text_tfidf = vectorizer.transform(dataframe['Cleaned_Text'])
    similarity_scores = cosine_similarity(input_tfidf, all_text_tfidf)[0]
    most_similar_indices = similarity_scores.argsort()[-3:][::-1]  # Get top 3 most similar
    similar_examples = dataframe.iloc[most_similar_indices][text_column_name].tolist()

    if prediction == 0:
        action_required = "No action required"
    elif prediction == 1:
        if probability > 0.7:
            action_required = "Ban the user account"
        else:
            action_required = "Restricting user to comment"

    return {
        "Input Text": input_text,
        "Prediction": prediction_label,
        "Similar Examples": similar_examples,
        "Action Required": action_required
    }

"""Getting User Input and Providing Output"""

from sklearn.metrics.pairwise import cosine_similarity
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer

def preprocess_text(text):
    """
    Preprocesses the input text by converting to lowercase, removing HTML tags,
    URLs, non-alphanumeric characters, and stop words, and lemmatizing the words.

    Args:
        text (str): The text to preprocess.

    Returns:
        str: The preprocessed text.
    """
    text = text.lower()
    text = re.sub(r'<.*?>', '', text)
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.IGNORECASE)
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    text = text.strip()
    tokens = word_tokenize(text)
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    return ' '.join(tokens)

def predict_and_get_action(input_text, model, vectorizer, dataframe):
    """
    Predicts cyberbullying and determines the action required, with detailed output.

    Args:
        input_text (str): The text to analyze.
        model: The trained machine learning model (MultinomialNB in this case).
        vectorizer: The fitted TF-IDF vectorizer.
        dataframe (pd.DataFrame): The original training dataframe.

    Returns:
        dict: A dictionary containing the analysis results, including:
            - "Input Text": The original input text.
            - "Prediction": "Cyberbullying" or "Non-Cyberbullying".
            - "Similar Examples": A list of 3-4 most similar text examples from the dataset.
            - "Label": The label of the most similar example from the dataset.
            - "Reason": The reason for the prediction, extracted from the similar examples.
            - "Action Required": The action to take: "Ban the user account", "Restrict user to comment", or "No action required".
    """
    preprocessed_input = preprocess_text(input_text)
    input_tfidf = vectorizer.transform([preprocessed_input])
    prediction = model.predict(input_tfidf)[0]
    probability = model.predict_proba(input_tfidf)[0][prediction]

    if prediction == 1:
        prediction_label = "Cyberbullying"
    else:
        prediction_label = "Non-Cyberbullying"

    # Find similar examples from the dataset
    all_text_tfidf = vectorizer.transform(dataframe['Cleaned_Text'])
    similarity_scores = cosine_similarity(input_tfidf, all_text_tfidf)[0]
    most_similar_indices = similarity_scores.argsort()[-4:][::-1]  # Get top 4 most similar
    similar_examples = dataframe.iloc[most_similar_indices] # Get the entire rows

    # Extract similar texts
    similar_texts = similar_examples['Text'].tolist()

    # Get the label of the *most* similar example.
    most_similar_label = dataframe.iloc[most_similar_indices[0]]['Is_Cyberbullying'] #Get label of top similar text.

    # Get the reason.  For simplicity, extract from the *most* similar example.
    reason = dataframe.iloc[most_similar_indices[0]]['Reason']  # Assuming a 'Reason' column exists

    if prediction == 0:
        action_required = "No action required"
    elif prediction == 1:
        if "sexual harassment" in reason.lower() or "hate speech" in reason.lower():
            action_required = "Ban the user account"
        else:
            action_required = "Restrict user to comment"
    else:
        action_required = "No action required" # default action

    return {
        "Input Text": input_text,
        "Prediction": prediction_label,
        "Similar Examples": similar_texts,
        "Label": most_similar_label,
        "Reason": reason,
        "Action Required": action_required,
        "Probability": probability
    }

# Load the dataset
data = pd.read_csv("cyberbullying_dataset.csv")

# Preprocess the text data
data['Cleaned_Text'] = data['Text'].apply(preprocess_text)

# Encode the labels
label_encoder = LabelEncoder()
data['Is_Cyberbullying_Encoded'] = label_encoder.fit_transform(data['Is_Cyberbullying'])


# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    data['Cleaned_Text'], data['Is_Cyberbullying_Encoded'], test_size=0.2, random_state=42, stratify=data['Is_Cyberbullying_Encoded']
)

# Extract features using TF-IDF
tfidf_vectorizer = TfidfVectorizer()
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Train the Naive Bayes model (Best Model)
nb_model = MultinomialNB()
nb_model.fit(X_train_tfidf, y_train)



# Main loop for user interaction
while True:
    user_input_text = input("Enter the text to check for cyberbullying (or type 'exit' to quit): ")
    if user_input_text.lower() == 'exit':
        break

    # Assuming nb_model, tfidf_vectorizer, and data are available from previous steps
    output = predict_and_get_action(user_input_text, nb_model, tfidf_vectorizer, data)

    print("\n--- Output ---")
    print(f"Input Text: {output['Input Text']}")
    print(f"Prediction: {output['Prediction']}")
    print(f"Probability: {output['Probability']:.4f}")
    print("\nSimilar Examples from Dataset:")
    for i, example in enumerate(output['Similar Examples']):
        print(f"{i+1}. {example}")
    print(f"Label of most similar text: {output['Label']}")
    print(f"Reason: {output['Reason']}")
    print(f"Action Required: {output['Action Required']}")

from sklearn.metrics.pairwise import cosine_similarity
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
import tkinter as tk
from tkinter import ttk
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import os

def preprocess_text(text):
    """
    Preprocesses the input text.
    """
    text = text.lower()
    text = re.sub(r'<.*?>', '', text)
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.IGNORECASE)
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    text = text.strip()
    tokens = word_tokenize(text)
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    return ' '.join(tokens)

def predict_and_get_action(input_text, model, vectorizer, dataframe):
    """
    Predicts cyberbullying and determines the action required.
    """
    preprocessed_input = preprocess_text(input_text)
    input_tfidf = vectorizer.transform([preprocessed_input])
    prediction = model.predict(input_tfidf)[0]
    probability = model.predict_proba(input_tfidf)[0][prediction]

    if prediction == 1:
        prediction_label = "Cyberbullying"
    else:
        prediction_label = "Non-Cyberbullying"

    all_text_tfidf = vectorizer.transform(dataframe['Cleaned_Text'])
    similarity_scores = cosine_similarity(input_tfidf, all_text_tfidf)[0]
    most_similar_indices = similarity_scores.argsort()[-4:][::-1]
    similar_examples = dataframe.iloc[most_similar_indices]
    similar_texts = similar_examples['Text'].tolist()
    most_similar_label = dataframe.iloc[most_similar_indices[0]]['Label']
    reason = dataframe.iloc[most_similar_indices[0]]['Reason']

    if prediction == 0:
        action_required = "No action required"
    elif prediction == 1:
        if "sexual harassment" in reason.lower() or "hate speech" in reason.lower():
            action_required = "Ban the user account"
        else:
            action_required = "Restrict user to comment"
    else:
        action_required = "No action required"

    return {
        "Input Text": input_text,
        "Prediction": prediction_label,
        "Probability": probability,
        "Similar Examples": similar_texts,
        "Label": most_similar_label,
        "Reason": reason,
        "Action Required": action_required,
    }

# Load the dataset
data = pd.read_csv("cyberbullying_dataset.csv")  # Replace with your dataset path

# Preprocess the text data
data['Cleaned_Text'] = data['Text'].apply(preprocess_text)

# Encode the labels.
label_encoder = LabelEncoder()
data['Is_Cyberbullying_Encoded'] = label_encoder.fit_transform(data['Is_Cyberbullying'])

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    data['Cleaned_Text'], data['Is_Cyberbullying_Encoded'], test_size=0.2, random_state=42,
    stratify=data['Is_Cyberbullying_Encoded']
)

# Extract features using TF-IDF
tfidf_vectorizer = TfidfVectorizer()
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Train the Naive Bayes model (Best Model)
nb_model = MultinomialNB()
nb_model.fit(X_train_tfidf, y_train)

# --- Visualization Functions ---
def create_bar_chart(probabilities, root):
    """
    Creates a bar chart of the prediction probabilities.

    Args:
        probabilities (list): A list of probabilities for each class.
        root (tk.Tk): The main Tkinter window.

    Returns:
        ttk.Frame: A frame containing the bar chart.
    """
    chart_frame = ttk.Frame(root)
    fig, ax = plt.subplots(figsize=(4, 3))  # Adjust size as needed
    ax.bar(['Non-Cyberbullying', 'Cyberbullying'], probabilities)
    ax.set_ylabel('Probability')
    ax.set_title('Prediction Probability')
    canvas = FigureCanvasTkAgg(fig, chart_frame)
    canvas.draw()
    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    return chart_frame

def create_table(similar_examples, root):
    """
    Creates a table of similar examples.

    Args:
        similar_examples (list): A list of similar text examples.
        root (tk.Tk): The main Tkinter window.

    Returns:
        ttk.Frame: A frame containing the table.
    """
    table_frame = ttk.Frame(root)
    tree = ttk.Treeview(table_frame, cols=('Example',), show='headings')
    tree.heading('Example', text='Similar Text')
    for example in similar_examples:
        tree.insert('', tk.END, values=(example,))
    tree.pack(fill=tk.BOTH, expand=True)
    return table_frame

def create_text_frame(text_data, root, title):
    """
    Creates a text frame to display text.

    Args:
        text_data (str): The text to display.
        root (tk.Tk): The main Tkinter window.
        title (str): Title of the frame

    Returns:
        ttk.Frame: A frame containing the text.
    """
    text_frame = ttk.Frame(root)
    label = ttk.Label(text_frame, text=title, font=('Arial', 12, 'bold'))
    text_widget = tk.Text(text_frame, wrap=tk.WORD, height=4, width=50) # Adjusted height
    text_widget.insert(tk.END, text_data)
    text_widget.config(state=tk.DISABLED)  # Make it read-only
    label.pack(pady=(0, 5), anchor='w')
    text_widget.pack(fill=tk.BOTH, expand=True)
    return text_frame

def create_output_frame(output_data, root):
    """
    Creates a frame to display the output.

    Args:
        output_data (dict): The output data.
        root (tk.Tk): The main Tkinter window.

    Returns:
        ttk.Frame: A frame containing the output.
    """
    output_frame = ttk.Frame(root)
    input_text_frame = create_text_frame(output_data['Input Text'], output_frame, "Input Text")
    prediction_frame = create_text_frame(output_data['Prediction'], output_frame, "Prediction")
    probability_chart = create_bar_chart([1- output_data['Probability'], output_data['Probability']], output_frame)
    similar_examples_table = create_table(output_data['Similar Examples'], output_frame)
    label_frame = create_text_frame(output_data['Label'], output_frame, "Label of most similar text")
    reason_frame = create_text_frame(output_data['Reason'], output_frame, "Reason")
    action_frame = create_text_frame(output_data['Action Required'], output_frame, "Action Required")

    input_text_frame.pack(pady=(10, 0), fill=tk.X)
    prediction_frame.pack(pady=(10, 0), fill=tk.X)
    probability_chart.pack(pady=(10, 0), fill=tk.X)
    similar_examples_table.pack(pady=(10, 0), fill=tk.X)
    label_frame.pack(pady=(10,0), fill=tk.X)
    reason_frame.pack(pady=(10, 0), fill=tk.X)
    action_frame.pack(pady=(10, 10), fill=tk.X)
    return output_frame

# --- Main Application ---
def main():
    # Check if a display is available
    if 'DISPLAY' not in os.environ:
        print("No display found.  Running in headless mode.  Visualization is disabled.")
        #  Fall back to a non-GUI mode.  This is essential for environments without a display.
        while True:
            user_input_text = input("Enter text to check for cyberbullying (or type 'exit' to quit): ")
            if user_input_text.lower() == 'exit':
                break
            output_data = predict_and_get_action(user_input_text, nb_model, tfidf_vectorizer, data)
            print("\n--- Output ---")
            print(f"Input Text: {output_data['Input Text']}")
            print(f"Prediction: {output_data['Prediction']}")
            print(f"Probability: {output_data['Probability']:.4f}")
            print("\nSimilar Examples from Dataset:")
            for i, example in enumerate(output_data['Similar Examples']):
                print(f"{i+1}. {example}")
            print(f"Label of most similar text: {output_data['Label']}")
            print(f"Reason: {output_data['Reason']}")
            print(f"Action Required: {output_data['Action Required']}")
        return

    # If a display is available, proceed with the GUI
    root = tk.Tk()
    root.title("Cyberbullying Detection Dashboard")
    main_frame = ttk.Frame(root, padding="20")
    main_frame.pack(fill=tk.BOTH, expand=True)

    output_frames = []  # List to store output frames

    def handle_input():
        user_input_text = text_entry.get()
        if not user_input_text:
            return  # prevent empty input

        output_data = predict_and_get_action(user_input_text, nb_model, tfidf_vectorizer, data)
        output_frame = create_output_frame(output_data, main_frame)
        output_frames.append(output_frame)  # Store the frame
        #pack the output frame
        output_frame.pack(pady=10, fill=tk.X)

        text_entry.delete(0, tk.END)  # Clear the entry field

    input_frame = ttk.Frame(main_frame)
    ttk.Label(input_frame, text="Enter text to check for cyberbullying:", font=('Arial', 10)).pack(pady=(0, 5), anchor='w')
    text_entry = ttk.Entry(input_frame, width=50)
    text_entry.pack(side=tk.LEFT, padx=(0, 10), fill=tk.X, expand=True)
    ttk.Button(input_frame, text="Check", command=handle_input).pack(side=tk.LEFT)
    input_frame.pack(pady=(0, 10), fill=tk.X)

    # Exit button to close the application
    ttk.Button(main_frame, text="Exit", command=root.destroy).pack(pady=(10, 0), anchor='e')

    root.mainloop()

if __name__ == "__main__":
    main()

from sklearn.metrics.pairwise import cosine_similarity
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
import tkinter as tk
from tkinter import ttk
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import os

def preprocess_text(text):
    """
    Preprocesses the input text.
    """
    text = text.lower()
    text = re.sub(r'<.*?>', '', text)
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.IGNORECASE)
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    text = text.strip()
    tokens = word_tokenize(text)
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    return ' '.join(tokens)

def predict_and_get_action(input_text, model, vectorizer, dataframe):
    """
    Predicts cyberbullying and determines the action required.
    """
    preprocessed_input = preprocess_text(input_text)
    input_tfidf = vectorizer.transform([preprocessed_input])
    prediction = model.predict(input_tfidf)[0]
    probability = model.predict_proba(input_tfidf)[0][prediction]

    if prediction == 1:
        prediction_label = "Cyberbullying"
    else:
        prediction_label = "Non-Cyberbullying"

    all_text_tfidf = vectorizer.transform(dataframe['Cleaned_Text'])
    similarity_scores = cosine_similarity(input_tfidf, all_text_tfidf)[0]
    most_similar_indices = similarity_scores.argsort()[-4:][::-1]
    similar_examples = dataframe.iloc[most_similar_indices]
    similar_texts = similar_examples['Text'].tolist()
    most_similar_label = dataframe.iloc[most_similar_indices[0]]['Label'] # Changed this line
    reason = dataframe.iloc[most_similar_indices[0]]['Reason']

    if prediction == 0:
        action_required = "No action required"
    elif prediction == 1:
        if "sexual harassment" in reason.lower() or "hate speech" in reason.lower():
            action_required = "Ban the user account"
        else:
            action_required = "Restrict user to comment"
    else:
        action_required = "No action required"

    return {
        "Input Text": input_text,
        "Prediction": prediction_label,
        "Probability": probability,
        "Similar Examples": similar_texts,
        "Label": most_similar_label, # Changed this line
        "Reason": reason,
        "Action Required": action_required,
    }

# Load the dataset
data = pd.read_csv("cyberbullying_dataset.csv")  # Replace with your dataset path

# Preprocess the text data
data['Cleaned_Text'] = data['Text'].apply(preprocess_text)

# Encode the labels.
label_encoder = LabelEncoder()
data['Is_Cyberbullying_Encoded'] = label_encoder.fit_transform(data['Is_Cyberbullying'])

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    data['Cleaned_Text'], data['Is_Cyberbullying_Encoded'], test_size=0.2, random_state=42,
    stratify=data['Is_Cyberbullying_Encoded']
)

# Extract features using TF-IDF
tfidf_vectorizer = TfidfVectorizer()
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Train the Naive Bayes model (Best Model)
nb_model = MultinomialNB()
nb_model.fit(X_train_tfidf, y_train)

# --- Visualization Functions ---
def create_bar_chart(probabilities, root):
    """
    Creates a bar chart of the prediction probabilities.

    Args:
        probabilities (list): A list of probabilities for each class.
        root (tk.Tk): The main Tkinter window.

    Returns:
        ttk.Frame: A frame containing the bar chart.
    """
    chart_frame = ttk.Frame(root)
    fig, ax = plt.subplots(figsize=(4, 3))  # Adjust size as needed
    ax.bar(['Non-Cyberbullying', 'Cyberbullying'], probabilities)
    ax.set_ylabel('Probability')
    ax.set_title('Prediction Probability')
    canvas = FigureCanvasTkAgg(fig, chart_frame)
    canvas.draw()
    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    return chart_frame

def create_table(similar_examples, root):
    """
    Creates a table of similar examples.

    Args:
        similar_examples (list): A list of similar text examples.
        root (tk.Tk): The main Tkinter window.

    Returns:
        ttk.Frame: A frame containing the table.
    """
    table_frame = ttk.Frame(root)
    tree = ttk.Treeview(table_frame, cols=('Example',), show='headings')
    tree.heading('Example', text='Similar Text')
    for example in similar_examples:
        tree.insert('', tk.END, values=(example,))
    tree.pack(fill=tk.BOTH, expand=True)
    return table_frame

def create_text_frame(text_data, root, title):
    """
    Creates a text frame to display text.

    Args:
        text_data (str): The text to display.
        root (tk.Tk): The main Tkinter window.
        title (str): Title of the frame

    Returns:
        ttk.Frame: A frame containing the text.
    """
    text_frame = ttk.Frame(root)
    label = ttk.Label(text_frame, text=title, font=('Arial', 12, 'bold'))
    text_widget = tk.Text(text_frame, wrap=tk.WORD, height=4, width=50) # Adjusted height
    text_widget.insert(tk.END, text_data)
    text_widget.config(state=tk.DISABLED)  # Make it read-only
    label.pack(pady=(0, 5), anchor='w')
    text_widget.pack(fill=tk.BOTH, expand=True)
    return text_frame

def create_output_frame(output_data, root):
    """
    Creates a frame to display the output.

    Args:
        output_data (dict): The output data.
        root (tk.Tk): The main Tkinter window.

    Returns:
        ttk.Frame: A frame containing the output.
    """
    output_frame = ttk.Frame(root)
    input_text_frame = create_text_frame(output_data['Input Text'], output_frame, "Input Text")
    prediction_frame = create_text_frame(output_data['Prediction'], output_frame, "Prediction")
    probability_chart = create_bar_chart([1- output_data['Probability'], output_data['Probability']], output_frame)
    similar_examples_table = create_table(output_data['Similar Examples'], output_frame)
    label_frame = create_text_frame(output_data['Label'], output_frame, "Label of most similar text") # Changed this line
    reason_frame = create_text_frame(output_data['Reason'], output_frame, "Reason")
    action_frame = create_text_frame(output_data['Action Required'], output_frame, "Action Required")

    input_text_frame.pack(pady=(10, 0), fill=tk.X)
    prediction_frame.pack(pady=(10, 0), fill=tk.X)
    probability_chart.pack(pady=(10, 0), fill=tk.X)
    similar_examples_table.pack(pady=(10, 0), fill=tk.X)
    label_frame.pack(pady=(10,0), fill=tk.X) # Changed this line
    reason_frame.pack(pady=(10, 0), fill=tk.X)
    action_frame.pack(pady=(10, 10), fill=tk.X)
    return output_frame

# --- Main Application ---
def main():
    # Check if a display is available
    if 'DISPLAY' not in os.environ:
        print("No display found.  Running in headless mode.  Visualization is disabled.")
        #  Fall back to a non-GUI mode.  This is essential for environments without a display.
        while True:
            user_input_text = input("Enter text to check for cyberbullying (or type 'exit' to quit): ")
            if user_input_text.lower() == 'exit':
                break
            output_data = predict_and_get_action(user_input_text, nb_model, tfidf_vectorizer, data)
            print("\n--- Output ---")
            print(f"Input Text: {output_data['Input Text']}")
            print(f"Prediction: {output_data['Prediction']}")
            print(f"Probability: {output_data['Probability']:.4f}")
            print("\nSimilar Examples from Dataset:")
            for i, example in enumerate(output_data['Similar Examples']):
                print(f"{i+1}. {example}")
            print(f"Label of most similar text: {output_data['Label']}") # Changed this line
            print(f"Reason: {output_data['Reason']}")
            print(f"Action Required: {output_data['Action Required']}")
        return

    # If a display is available, proceed with the GUI
    root = tk.Tk()
    root.title("Cyberbullying Detection Dashboard")
    main_frame = ttk.Frame(root, padding="20")
    main_frame.pack(fill=tk.BOTH, expand=True)

    output_frames = []  # List to store output frames

    def handle_input():
        user_input_text = text_entry.get()
        if not user_input_text:
            return  # prevent empty input

        output_data = predict_and_get_action(user_input_text, nb_model, tfidf_vectorizer, data)
        output_frame = create_output_frame(output_data, main_frame)
        output_frames.append(output_frame)  # Store the frame
        #pack the output frame
        output_frame.pack(pady=10, fill=tk.X)

        text_entry.delete(0, tk.END)  # Clear the entry field

    input_frame = ttk.Frame(main_frame)
    ttk.Label(input_frame, text="Enter text to check for cyberbullying:", font=('Arial', 10)).pack(pady=(0, 5), anchor='w')
    text_entry = ttk.Entry(input_frame, width=50)
    text_entry.pack(side=tk.LEFT, padx=(0, 10), fill=tk.X, expand=True)
    ttk.Button(input_frame, text="Check", command=handle_input).pack(side=tk.LEFT)
    input_frame.pack(pady=(0, 10), fill=tk.X)

    # Exit button to close the application
    ttk.Button(main_frame, text="Exit", command=root.destroy).pack(pady=(10, 0), anchor='e')

    root.mainloop()

if __name__ == "__main__":
    main()

